{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1f97b1b-c32c-493c-b1c9-96cbeafe7db7",
   "metadata": {},
   "source": [
    "# Patent source for the InnoClass Pipeline in Dagster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077adab4-5d50-4a2a-b974-29f6804a0465",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to select the patent data that will be send to the pipeline on the main server.\n",
    "The use of the EPAB library, especially the use of BigQuery directly, gives more flexibility to select proper distributions of data depending to their date, length,..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f332474e-58fc-4742-8c24-a36d9b944c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from epo.tipdata.epab import EPABClient\n",
    "epab = EPABClient(env=\"PROD\")\n",
    "import re\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import (\n",
    "    HTML, IntText, Text, Dropdown, SelectMultiple, Checkbox, Button, VBox, HBox, Layout\n",
    ")\n",
    "from IPython.display import display\n",
    "import pickle\n",
    "import json\n",
    "import gzip\n",
    "import subprocess\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300fbde6-9fc4-46a5-9c78-1e45cf0d3c46",
   "metadata": {},
   "source": [
    "Patents data querying\n",
    "\n",
    "First we test here different methods to load representative sets of patents for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95073316-bb1b-48c8-a9e2-f4b47dda34da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions to load and save lists of dictionaries to a gzipped jsonl FILE\n",
    "#-----------------------------\n",
    "def save_list(data, metadata,filename):\n",
    "    \"\"\"\n",
    "    Saves a list of dictionaries to a gzipped JSON Lines (jsonl) file.\n",
    "\n",
    "    Parameters:\n",
    "        data (list): List of dictionaries to be saved.\n",
    "        filename (str): The filename (including .gz if desired) where the data will be saved.\n",
    "    \"\"\"\n",
    "    with gzip.open(filename, 'wt', encoding='utf-8') as f:\n",
    "        # Dump the metadata dictionary to a JSON string and then add the newline\n",
    "        f.write(json.dumps(metadata) + \"\\n\")\n",
    "        for item in data:\n",
    "            # Write each dictionary as a JSON line.\n",
    "            f.write(json.dumps(item) + \"\\n\")\n",
    "\n",
    "def load_list(filename):\n",
    "    \"\"\"\n",
    "    Loads a gzipped JSON Lines (jsonl) file, separating the first line as metadata\n",
    "    and the rest as a list of dictionaries.\n",
    "\n",
    "    Parameters:\n",
    "        filename (str): The filename of the gzipped jsonl file.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - dict: The metadata dictionary from the first line.\n",
    "            - list: A list of dictionaries (data records) read from the file.\n",
    "    \"\"\"\n",
    "    metadata = {}\n",
    "    data_records = []\n",
    "    \n",
    "    with gzip.open(filename, 'rt', encoding='utf-8') as f:\n",
    "        # Read the first line as metadata\n",
    "        first_line = f.readline()\n",
    "        if first_line:\n",
    "            try:\n",
    "                metadata = json.loads(first_line)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Warning: Could not decode first line as metadata: {e}\")\n",
    "                pass     \n",
    "        # Read the rest of the lines as data records\n",
    "        for line in f:\n",
    "            try:\n",
    "                data_records.append(json.loads(line))\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Warning: Could not decode line as JSON, skipping: {line.strip()} - {e}\")\n",
    "                continue # Skip malformed lines\n",
    "\n",
    "    return metadata, data_records\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a9662e-5cfb-4f97-b7e5-688fd5fd8197",
   "metadata": {},
   "source": [
    "## REQUESTING PATENTS FROM EPO DATABASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd7e06c5-836b-46e0-a736-11cd2403c202",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sql_request_random(params):\n",
    "    num_files=params[\"nbr\"]\n",
    "    nbrextract=params[\"nbrextract\"]\n",
    "    statement = f\"\"\"\n",
    "          SELECT epab_doc_id, LEFT(description.text, {nbrextract}) as description, publication.date as pubdate, publication.number as pubnbr, title.en as title\n",
    "        FROM `{epab.full_table_name}`\n",
    "        WHERE description.language=\"EN\"\n",
    "        ORDER BY RAND()\n",
    "        LIMIT {num_files};\"\"\"\n",
    "    return statement\n",
    "\n",
    "def create_sql_request_ipc(params):\n",
    "    num_files=params[\"nbr\"]\n",
    "    nbrextract=params[\"nbrextract\"]\n",
    "    query=f\"\"\"WITH flattened AS (\n",
    "      SELECT\n",
    "        epab_doc_id, \n",
    "        ipc_struct.symbol AS ipc_class\n",
    "      FROM `{epab.full_table_name}`,\n",
    "           UNNEST(ipc) AS ipc_struct\n",
    "    ),\n",
    "    stratified_sample AS (\n",
    "      SELECT\n",
    "        ipc_class,\n",
    "        epab_doc_id,\n",
    "        LEFT(description.text, {nbrextract}) as description,\n",
    "        publication.date as pubdate, publication.number as pubnbr, title.en as title\n",
    "        ROW_NUMBER() OVER(PARTITION BY ipc_class ORDER BY RAND() LIMIT {num_files}) AS rn\n",
    "      FROM flattened\n",
    "        WHERE description.language=\"EN\"\n",
    "    )\n",
    "    SELECT\n",
    "      ipc_class,\n",
    "      epab_doc_id,\n",
    "      pubdate, pubnbr, description, title\n",
    "    FROM stratified_sample\n",
    "    WHERE rn = 1;\"\"\"\n",
    "    return query\n",
    "\n",
    "def create_sql_request_date(params):\n",
    "    nbrextract=params[\"nbrextract\"]\n",
    "    num_files=params[\"nbr\"]\n",
    "    statement = f\"\"\"\n",
    "   DECLARE num_files INT64 DEFAULT {num_files};\n",
    "\n",
    "WITH DateRange AS (\n",
    "  SELECT\n",
    "    MIN(TIMESTAMP(PARSE_DATE('%Y%m%d', publication.date))) AS min_timestamp,\n",
    "    CURRENT_TIMESTAMP() AS max_timestamp\n",
    "  FROM\n",
    "    `{epab.full_table_name}`\n",
    "  WHERE publication.date IS NOT NULL -- Handle nulls\n",
    "),\n",
    "DateBuckets AS (\n",
    "  SELECT\n",
    "    TIMESTAMP(DATE_ADD(DATE(DateRange.min_timestamp), INTERVAL CAST(offset * (DATE_DIFF(DateRange.max_timestamp, DateRange.min_timestamp, DAY) / 10) AS INT64) DAY)) AS bucket_start,\n",
    "    TIMESTAMP(DATE_ADD(DATE(DateRange.min_timestamp), INTERVAL CAST((offset + 1) * (DATE_DIFF(DateRange.max_timestamp, DateRange.min_timestamp, DAY) / 10) AS INT64) DAY)) AS bucket_end\n",
    "  FROM\n",
    "    DateRange,\n",
    "    UNNEST(GENERATE_ARRAY(0, 9)) AS offset\n",
    "),\n",
    "GroupedData AS (\n",
    "  SELECT\n",
    "    epab_doc_id,\n",
    "    LEFT(description.text, {nbrextract}) as description, publication.number as pubnbr,\n",
    "    publication.date as pubdate, title.en as title\n",
    "    TIMESTAMP(PARSE_DATE('%Y%m%d', publication.date)) as publication_timestamp,\n",
    "    bucket_start,\n",
    "    bucket_end\n",
    "  FROM\n",
    "    `{epab.full_table_name}`\n",
    "  JOIN\n",
    "    DateBuckets\n",
    "  ON\n",
    "    TIMESTAMP(PARSE_DATE('%Y%m%d', publication.date)) >= bucket_start AND TIMESTAMP(PARSE_DATE('%Y%m%d', publication.date)) < bucket_end\n",
    "  WHERE description.language=\"EN\" AND publication.date IS NOT NULL\n",
    "),\n",
    "SampledData AS (\n",
    "  SELECT\n",
    "    epab_doc_id,\n",
    "    description,\n",
    "    pubdate, pubnbr, title\n",
    "    bucket_start\n",
    "  FROM\n",
    "    GroupedData\n",
    "  QUALIFY ROW_NUMBER() OVER (PARTITION BY bucket_start ORDER BY RAND()) <= (num_files / 10)\n",
    ")\n",
    "SELECT\n",
    "  epab_doc_id,\n",
    "  description,\n",
    "  pubdate, pubnbr, title\n",
    "FROM\n",
    "  SampledData;\"\"\"\n",
    "    return statement\n",
    "\n",
    "def create_sql_request_sdg(params):\n",
    "    statement = f\"\"\"\n",
    "          SELECT epab_doc_id,  description.text as description, publication.date as pubdate, publication.number as pubnbr,title.en as title\n",
    "        FROM `{epab.full_table_name}`\n",
    "        WHERE LOWER(description.text) LIKE '%sustainable development goal%'\"\"\"\n",
    "\n",
    "    return statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0dfa4e0-17df-4f61-bb9e-67ede7c1bb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def find_sdg_numbers(text):\n",
    "    \"\"\"\n",
    "    Finds all unique Sustainable Development Goal (SDG) numbers in a given text,\n",
    "    checking for both \"sustainable development goal XX\" and \"SDG XX\" patterns.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input document text.\n",
    "\n",
    "    Returns:\n",
    "        set: A set of unique SDG numbers found in the text.\n",
    "    \"\"\"\n",
    "    # Pattern to find \"sustainable development goal XX\" OR \"SDG XX\"\n",
    "    # (sustainable development goal|SDG) - This is a non-capturing group for the alternatives.\n",
    "    # \\s* - Matches zero or more whitespace characters between \"goal\" or \"SDG\" and the number.\n",
    "    # (\\d+) - Captures the number (one or more digits).\n",
    "    # re.IGNORECASE makes the search case-insensitive for both parts of the pattern.\n",
    "    pattern = re.compile(r\"(goal|SDG)\\s*(\\d+)\", re.IGNORECASE)\n",
    "\n",
    "    # Find all matches in the text\n",
    "    matches = pattern.finditer(text)\n",
    "\n",
    "    sdg_numbers = set() # Use a set to store unique numbers\n",
    "\n",
    "    for match in matches:\n",
    "        # match.group(2) because the first capturing group is (sustainable development goal|SDG)\n",
    "        # and the second capturing group is (\\d+)\n",
    "        sdg_number = int(match.group(2))\n",
    "        sdg_numbers.add(sdg_number) # Add to the set\n",
    "\n",
    "    return sdg_numbers\n",
    "\n",
    "import re\n",
    "\n",
    "OFFICIAL_SDG_DESCRIPTIONS = {\n",
    "    1: \"End poverty in all its forms everywhere.\",\n",
    "    2: \"End hunger, achieve food security and improved nutrition and promote sustainable agriculture.\",\n",
    "    3: \"Ensure healthy lives and promote well-being for all at all ages.\",\n",
    "    4: \"Ensure inclusive and equitable quality education and promote lifelong learning opportunities for all.\",\n",
    "    5: \"Achieve gender equality and empower all women and girls.\",\n",
    "    6: \"Ensure availability and sustainable management of water and sanitation for all.\",\n",
    "    7: \"Ensure access to affordable, reliable, sustainable and modern energy for all.\",\n",
    "    8: \"Promote sustained, inclusive and sustainable economic growth, full and productive employment and decent work for all.\",\n",
    "    9: \"Build resilient infrastructure, promote inclusive and sustainable industrialization and foster innovation.\",\n",
    "    10: \"Reduce inequality within and among countries.\",\n",
    "    11: \"Make cities and human settlements inclusive, safe, resilient and sustainable.\",\n",
    "    12: \"Ensure sustainable consumption and production patterns.\",\n",
    "    13: \"Take urgent action to combat climate change and its impacts.\",\n",
    "    14: \"Conserve and sustainably use the oceans, seas and marine resources for sustainable development.\",\n",
    "    15: \"Protect, restore and promote sustainable use of terrestrial ecosystems, sustainably manage forests, combat desertification, and halt and reverse land degradation and halt biodiversity loss.\",\n",
    "    16: \"Promote peaceful and inclusive societies for sustainable development, provide access to justice for all and build effective, accountable and inclusive institutions at all levels.\",\n",
    "    17: \"Strengthen the means of implementation and revitalize the Global Partnership for Sustainable Development.\"\n",
    "    }\n",
    "# Define the 17 Sustainable Development Goal descriptions\n",
    "# Using a dictionary for easy lookup by number\n",
    "SDG_DESCRIPTIONS = {\n",
    "    1: \"No Poverty\",\n",
    "    2: \"Zero Hunger\",\n",
    "    3: \"Good Health and Well-being\",\n",
    "    4: \"Quality Education\",\n",
    "    5: \"Gender Equality\",\n",
    "    6: \"Clean Water and Sanitation\",\n",
    "    7: \"Affordable and Clean Energy\",\n",
    "    8: \"Decent Work and Economic Growth\",\n",
    "    9: \"Industry, Innovation and Infrastructure\",\n",
    "    10: \"Reduced Inequalities\",\n",
    "    11: \"Sustainable Cities and Communities\",\n",
    "    12: \"Responsible Consumption and Production\",\n",
    "    13: \"Climate Action\",\n",
    "    14: \"Life Below Water\",\n",
    "    15: \"Life on Land\",\n",
    "    16: \"Peace, Justice and Strong Institutions\",\n",
    "    17: \"Partnerships for the Goals\"\n",
    "}\n",
    "\n",
    "def find_sdg_numbers_direct(text):\n",
    "    \"\"\"\n",
    "    Finds all unique Sustainable Development Goal (SDG) numbers in a given text,\n",
    "    checking for both \"sustainable development goal XX\" and \"SDG XX\" patterns.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input document text.\n",
    "\n",
    "    Returns:\n",
    "        set: A set of unique SDG numbers directly mentioned in the text.\n",
    "    \"\"\"\n",
    "    pattern = re.compile(r\"(goal|SDG)\\s*(\\d+)\", re.IGNORECASE)\n",
    "    matches = pattern.finditer(text)\n",
    "    sdg_numbers = set()\n",
    "    for match in matches:\n",
    "        sdg_number = int(match.group(2))\n",
    "        sdg_numbers.add(sdg_number)\n",
    "    return sdg_numbers\n",
    "\n",
    "def find_sdg_numbers_from_description(full_description_text):\n",
    "    \"\"\"\n",
    "    Finds SDG numbers by searching for the text of SDG descriptions within\n",
    "    a given full description text.\n",
    "\n",
    "    Args:\n",
    "        full_description_text (str): The full description text of a document.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of SDG numbers found based on their description text.\n",
    "              (Can contain duplicates if a description is found multiple times).\n",
    "    \"\"\"\n",
    "    found_sdgs_by_description = []\n",
    "    # Create a case-insensitive regex pattern for each SDG description\n",
    "    # Ensure word boundaries to avoid partial matches (e.g., \"life\" matching part of \"wildlife\")\n",
    "    # Adding \\b for word boundaries. For multi-word descriptions, the internal spaces are fine.\n",
    "    # We escape any special regex characters in the description just in case.\n",
    "    for sdg_num, sdg_desc in SDG_DESCRIPTIONS.items():\n",
    "        # Escape potential regex special characters in the description\n",
    "        escaped_desc = re.escape(sdg_desc)\n",
    "        # Use a regex that allows for slight variations like punctuation around the words\n",
    "        # \\b ensures whole word match, but for longer phrases, we want the exact phrase.\n",
    "        # So we'll use a slightly more flexible approach, matching the phrase itself.\n",
    "        # Using re.finditer to find all occurrences\n",
    "        desc_pattern = re.compile(rf\"{escaped_desc}\", re.IGNORECASE)\n",
    "        \n",
    "        for match in desc_pattern.finditer(full_description_text):\n",
    "            found_sdgs_by_description.append(sdg_num)\n",
    "            \n",
    "    return found_sdgs_by_description\n",
    "\n",
    "def process_documents_for_sdgs(documents_data):\n",
    "\n",
    "    processed_results = []\n",
    "    for doc in documents_data:\n",
    "        doc_id = doc.get('pubnbr', 'N/A')\n",
    "        doc[\"original_text\"]=doc[\"description\"]\n",
    "        del doc[\"description\"]\n",
    "        text = doc.get('original_text', '')\n",
    "        full_description = doc.get('original_text', '')\n",
    "\n",
    "        # 1. Find SDG numbers directly from the main 'text'\n",
    "        direct_sdgs = find_sdg_numbers_direct(text)\n",
    "\n",
    "\n",
    "        description_sdgs = []\n",
    "        # 2. If no direct SDGs found, look in the 'full_description'\n",
    "        if not direct_sdgs:\n",
    "            description_sdgs = find_sdg_numbers_from_description(full_description)\n",
    "        \n",
    "        # Combine all found SDGs and get unique ones\n",
    "        all_unique_sdgs = set(direct_sdgs) # Start with direct SDGs\n",
    "        if description_sdgs:\n",
    "            all_unique_sdgs.update(description_sdgs) # Add description-based SDGs\n",
    "        classes=sorted(list(all_unique_sdgs))\n",
    "\n",
    "        result=[]\n",
    "        for value in classes:\n",
    "            result.append({\"value\": \"SDG\"+str(value), \"score\": 1})\n",
    "        doc[\"sdg\"]=result\n",
    "        doc[\"reference\"]=True\n",
    "        if len(result)==0 or len(result)==17:\n",
    "            doc[\"validation\"]=False\n",
    "        else:\n",
    "            doc[\"validation\"]=True\n",
    "        doc[\"id\"]=doc['epab_doc_id']\n",
    "        processed_results.append(doc)\n",
    "\n",
    "    return processed_results\n",
    "\n",
    "           \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d73598d-ae34-4518-8bd7-1513703fdf69",
   "metadata": {},
   "source": [
    "Enter here the filename to save raw patent descriptions requested from the database. The purpose is to avoid permanently sending requests to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa50559d-8b92-4fd3-82f5-5831ff88f39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main function to create and send the request to the database\n",
    "def query_raw(params):\n",
    "    data_selec=params[\"extract_method\"]\n",
    "    if data_selec==\"Random\":\n",
    "        statement=create_sql_request_random(params)\n",
    "        print(statement)\n",
    "    if data_selec==\"IPC\":\n",
    "        statement=create_sql_request_ipc(params)\n",
    "    if data_selec==\"Date\":\n",
    "        statement=create_sql_request_date(params)\n",
    "    if data_selec==\"SDG\":\n",
    "        statement=create_sql_request_sdg(params)\n",
    "    results = epab.sql_query(statement) \n",
    "    #TODO add CPC and other interesting metrics parameters\n",
    "    if data_selec!=\"SDG\":\n",
    "        docs = [{'id': item['epab_doc_id'], 'original_text': item['description'], 'pubdate':item['pubdate'],'pubnbr':item['pubnbr'],'title':item['title'],'cleaned_text':'','sdg':[{'value':'','score':0.}],'target':[{'value':'','score':0.}],'thumbsup':0,'thumbsdown':0,'reference':False,'validation':False} for item in results]\n",
    "    else:\n",
    "        docs=process_documents_for_sdgs(results)\n",
    "        for item in docs:\n",
    "            print(item[\"sdg\"])\n",
    "    save_list(docs,params,params[\"filename\"])\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1826e455-7ff8-4301-833b-dc60f029509b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_data_to_server(filename):\n",
    "    # Load environment variables from .env file\n",
    "    load_dotenv()\n",
    "    # Define a variable based on a value from .env\n",
    "    server = os.getenv(\"server\")\n",
    "    username=os.getenv(\"username\")\n",
    "    remote_host=username+\"@\"+server\n",
    "    remote_path = \"/home/codechallenge/InnoClass/backend/classEngine/data/\"\n",
    "    command = [\"scp\", filename, f\"{remote_host}:{remote_path}\"]\n",
    "    try:\n",
    "        print(\"command 1 : \")\n",
    "        process = subprocess.Popen(command, stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "        stdout, stderr = process.communicate() # Append newline to password\n",
    "        return_code = process.returncode\n",
    "        if return_code == 0:\n",
    "            print(\"SCP command executed successfully.\")\n",
    "            print(\"Output:\", stdout)\n",
    "        else:\n",
    "            print(f\"SCP command failed with error (code {return_code}):\")\n",
    "            print(\"Error!:\", stderr)\n",
    "   \n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: scp command not found.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9047256-63ee-4e96-8b9e-bdbf8dd05a63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dac28ed7ec2b4c4e8200e2ff63872981",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Text(value='', description='File Name:', placeholder='Enter file name', style=TextStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define a style with a wider description width\n",
    "style = {'description_width': '150px'}  # Increase as needed\n",
    "\n",
    "# Create form widgets with the updated style\n",
    "file_name_widget = widgets.Text(\n",
    "    value='',\n",
    "    description='File Name:',\n",
    "    placeholder='Enter file name',\n",
    "    style=style\n",
    ")\n",
    "\n",
    "number_widget = widgets.IntText(\n",
    "    value=10,\n",
    "    description='Number of patents:',\n",
    "    style=style\n",
    ")\n",
    "\n",
    "numberextract_widget = widgets.IntText(\n",
    "    value=5000,\n",
    "    description='Number of characters:',\n",
    "    style=style\n",
    ")\n",
    "\n",
    "extraction_widget = widgets.Dropdown(\n",
    "    options=[\"Random\", \"IPC\", \"Date\",\"SDG\"],\n",
    "    description='Extraction method:',\n",
    "    style=style\n",
    ")\n",
    "\n",
    "data_widget=widgets.Output()\n",
    "\n",
    "start_button = widgets.Button(\n",
    "    description='Start',\n",
    "    button_style='success'\n",
    ")\n",
    "\n",
    "# Define the function to be executed when the button is clicked\n",
    "def on_start_clicked(b):\n",
    "    params = {\n",
    "        \"filename\": file_name_widget.value,\n",
    "        \"nbr\": number_widget.value,\n",
    "        \"nbrextract\": numberextract_widget.value,\n",
    "        \"extract_method\": extraction_widget.value\n",
    "    }\n",
    "\n",
    "    print(\"querying\")\n",
    "    typereq=query_raw(params)\n",
    "    print(\"sending data\")\n",
    "    send_data_to_server(params[\"filename\"])\n",
    "\n",
    "start_button.on_click(on_start_clicked)\n",
    "\n",
    "# Display the form\n",
    "\n",
    "form_items = widgets.VBox([\n",
    "    file_name_widget,\n",
    "    number_widget,\n",
    "    numberextract_widget,\n",
    "    extraction_widget,\n",
    "    start_button,\n",
    "    data_widget\n",
    "])\n",
    "\n",
    "def update_filename(change):\n",
    "    selected_method = change.new\n",
    "    if selected_method == \"Random\":\n",
    "        file_name_widget.value = \"raw_data.tar.gz\"\n",
    "    elif selected_method == \"IPC\":\n",
    "        file_name_widget.value = \"raw_data.tar.gz\"\n",
    "    elif selected_method == \"Date\":\n",
    "        file_name_widget.value = \"raw_data.tar.gz\"\n",
    "    elif selected_method == \"SDG\":\n",
    "        file_name_widget.value = \"sdg_data.dat.gz\"\n",
    "    else:\n",
    "        file_name_widget.value = \"\" # Default or empty if no match\n",
    "extraction_widget.observe(update_filename, names='value')\n",
    "display(form_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec486f89-3b7b-4261-b1fe-ed74996db769",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06040d88-6367-4b26-8485-e35b0507afe8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
